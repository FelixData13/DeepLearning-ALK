{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Let us dig into tensors.\n",
    "\n",
    "Some of the examples are from [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Data representations for neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Scalars (rank-0 tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(12)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array(12)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Vectors (rank-1 tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  3,  6, 14,  7])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([12, 3, 6, 14, 7])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Matrices (rank-2 tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[5, 78, 2, 34, 0],\n",
    "              [6, 79, 3, 35, 1],\n",
    "              [7, 80, 4, 36, 2]])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Rank-3 and higher-rank tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "              [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "              [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]]])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Key attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Displaying the fourth digit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "digit = train_images[4]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Manipulating tensors in NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100, :, :]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100, 0:28, 0:28]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "my_slice = train_images[:, 14:, 14:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "my_slice = train_images[:, 7:-7, 7:-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 14, 14)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit = my_slice[0]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The notion of data batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "batch = train_images[:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "batch = train_images[128:256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "n = 3\n",
    "batch = train_images[128 * n:128 * (n + 1)] #take one batch and move forward by 128 for the next batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## The gears of neural networks: tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Element-wise operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/relu.png\" alt=\"Relu Activation\" style=\"width:600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_relu(x):\n",
    "    assert len(x.shape) == 2\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] = max(x[i, j], 0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_add(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert x.shape == y.shape\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[i, j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 0.02 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "x = np.random.random((20, 100))\n",
    "y = np.random.random((20, 100))\n",
    "\n",
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    z = x + y\n",
    "    z = np.maximum(z, 0.)\n",
    "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 2.21 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    z = naive_add(x, y)\n",
    "    z = naive_relu(z)\n",
    "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.random.random((32, 10))\n",
    "y = np.random.random((10,))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.expand_dims(y, axis=0)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.concatenate([y] * 32, axis=0)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576],\n",
       "       [0.67116832, 0.32142499, 0.28024804, 0.64269579, 0.9763601 ,\n",
       "        0.33838143, 0.63990441, 0.8319258 , 0.22413206, 0.08517576]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_add_matrix_and_vector(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 3, 32, 10)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.random.random((64, 3, 32, 10))\n",
    "y = np.random.random((32, 10))\n",
    "z = np.maximum(x, y)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Tensor product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((), 11.033698285522497)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.random((32,))\n",
    "y = np.random.random((32,))\n",
    "z = np.dot(x, y)                # dot product \n",
    "(z.shape, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_vector_dot(x, y):\n",
    "    assert len(x.shape) == 1\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[0] == y.shape[0]\n",
    "    z = 0.\n",
    "    for i in range(x.shape[0]):\n",
    "        z += x[i] * y[i]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_matrix_vector_dot(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            z[i] += x[i, j] * y[j]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_matrix_vector_dot(x, y):\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        z[i] = naive_vector_dot(x[i, :], y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_matrix_dot(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 2\n",
    "    #here 0 - row, 1 - column, as [2,3], means 2 row, 3 column\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    z = np.zeros((x.shape[0], y.shape[1]))\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(y.shape[1]):\n",
    "            row_x = x[i, :]\n",
    "            column_y = y[:, j]\n",
    "            z[i, j] = naive_vector_dot(row_x, column_y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/dot-product- matrix.png\" alt=\"Matrix Multiplication\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Tensor reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[0., 1.],\n",
    "             [2., 3.],\n",
    "             [4., 5.]])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [5.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape((6, 1))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 300)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.zeros((300, 20))\n",
    "x = np.transpose(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## The engine of neural networks: gradient-based optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent in a nuttshell:\n",
    "1. Draw a batch of training samples from the training data x, and corresponding targets, y_true. This is data points and its corresponding labels. In case of MNIST: Picture and the number it represents.\n",
    "2. Run the model on the training batch, x (a step called the forward pass) to obtain predictions from the network, y_pred.\n",
    "3. Compute the loss of the model on the batch, a measure of the mismatch between y_pred and y_true for all of the training examples.\n",
    "4. Propagate the loss backwards to see how much loss is caused by which network elements (a step called the backward pass)\n",
    "5. Update all weights of the model (this means possibly all weights in all the layers) in a way that slightly reduces the loss on this batch, drawing from the knowledge from the previous point.  \n",
    "\n",
    "More math on backprop: https://tashfeen.org/net/two.html?msclkid=055d51edc08811ec94003a20a4a39f74"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/gradient-descent-2d.png\" alt=\"Gradient Descent\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The gradient tape in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.Variable(0.)\n",
    "with tf.GradientTape() as tape:\n",
    "    y = 2 * x + 3\n",
    "grad_of_y_wrt_x = tape.gradient(y, x)\n",
    "grad_of_y_wrt_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 2.],\n",
       "       [2., 2.]], dtype=float32)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(tf.random.uniform((2, 2)))\n",
    "with tf.GradientTape() as tape:\n",
    "    y = 2 * x + 3\n",
    "grad_of_y_wrt_x = tape.gradient(y, x)\n",
    "grad_of_y_wrt_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[1.6105582, 1.6105582],\n",
       "        [0.9803499, 0.9803499]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 2.], dtype=float32)>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = tf.Variable(tf.random.uniform((2, 2)))\n",
    "b = tf.Variable(tf.zeros((2,)))\n",
    "x = tf.random.uniform((2, 2))\n",
    "with tf.GradientTape() as tape:\n",
    "    y = tf.matmul(x, W) + b\n",
    "grad_of_y_wrt_W_and_b = tape.gradient(y, [W, b])\n",
    "grad_of_y_wrt_W_and_b"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter02_mathematical-building-blocks.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
