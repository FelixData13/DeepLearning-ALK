{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Lets see how else we can build models.\n",
    "\n",
    "Some of the examples are from [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Different ways to build Keras models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras - easy to start with but also possible to provide deep dives for those who need it.  \n",
    "NLP and Image Processing are such needs.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The `Sequential` class**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thing to remember - Keras is API based.  \n",
    "Sequential is a list of stacked layers - there lies its first limitation.\n",
    "So:\n",
    "1. Only feedforward models.\n",
    "2. Only one input (not for example a text/picture and its metadata)\n",
    "3. Only one output (not for example multiple regression/classification predictions for one data point)\n",
    "4. Linear topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Incrementally building a Sequential model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like in Python list!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error - model is not built yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Calling a model for the first time to build it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.build(input_shape=(None, 3))\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The summary method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Naming models and layers with the `name` argument**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can name every layer, model and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_example_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_first_layer (Dense)      (None, 64)                256       \n",
      "                                                                 \n",
      " my_last_layer (Dense)       (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name=\"my_example_model\")\n",
    "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
    "model.build((None, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Specifying the input shape of your model in advance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that you can see the summary without actually building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple Functional model with two `Dense` layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what we did - add another layer on top of the previous one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = layers.Dense(64, activation=\"relu\")(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 64])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_input (InputLayer)       [(None, 3)]               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Multi-input, multi-output models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A multi-input, multi-output Functional model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets image a usecase of dealing with support tickets.  \n",
    "We need to move tickets to appropriate departaments. What we know:  \n",
    "1. Title of ticket (text)\n",
    "2. Text of the ticket (text)\n",
    "3. Tags added by the user (one-hot encoding)\n",
    "\n",
    "We expect to know:\n",
    "1. Priority of the ticket (regression)\n",
    "2. Departament where to move the ticket (classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 10000 #this is what we did on bert - how many words do we use from the dictionary\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "\n",
    "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
    "\n",
    "features = layers.Concatenate()([title, text_body, tags])\n",
    "features = layers.Dense(64, activation=\"relu\")(features)\n",
    "\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(\n",
    "    num_departments, activation=\"softmax\", name=\"department\")(features)\n",
    "\n",
    "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Training a multi-input, multi-output model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing lists of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 21ms/step - loss: 21.9741 - priority_loss: 0.3349 - department_loss: 21.6392 - priority_mean_absolute_error: 0.5032 - department_accuracy: 0.2242\n",
      "40/40 [==============================] - 1s 8ms/step - loss: 23.2868 - priority_loss: 0.3454 - department_loss: 22.9414 - priority_mean_absolute_error: 0.5125 - department_accuracy: 0.2578\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1280\n",
    "\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
    "\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit([title_data, text_body_data, tags_data],\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate([title_data, text_body_data, tags_data],\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing dicts of input & target arrays**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are using names - for complex models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 22ms/step - loss: 31.4611 - priority_loss: 0.3169 - department_loss: 31.1442 - priority_mean_absolute_error: 0.4839 - department_accuracy: 0.2727\n",
      "40/40 [==============================] - 1s 8ms/step - loss: 46.4265 - priority_loss: 0.3205 - department_loss: 46.1060 - priority_mean_absolute_error: 0.4875 - department_accuracy: 0.1102\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"},\n",
    "              metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]})\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "          {\"priority\": priority_data, \"department\": department_data},\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "               {\"priority\": priority_data, \"department\": department_data})\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The power of the Functional API: Access to layer connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Plot Model](../img/plot-ticketmodel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://www.manning.com/books/deep-learning-with-python  \n",
    "\n",
    "This can mean retrieving fetures from another models and reusing components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Retrieving the inputs or outputs of a layer in a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x1c9f91339a0>,\n",
       " <keras.engine.input_layer.InputLayer at 0x1c9f9133a00>,\n",
       " <keras.engine.input_layer.InputLayer at 0x1c9f9122c70>,\n",
       " <keras.layers.merge.Concatenate at 0x1c9f9122340>,\n",
       " <keras.layers.core.dense.Dense at 0x1c9d38da070>,\n",
       " <keras.layers.core.dense.Dense at 0x1c9d38daf40>,\n",
       " <keras.layers.core.dense.Dense at 0x1c9fa12db80>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'title')>,\n",
       " <KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'text_body')>,\n",
       " <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'tags')>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 20100) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a new model by reusing intermediate layer outputs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding new prediction to the existing model. Easy! \n",
    "Now: 3 categories of difficulty resolving the ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = model.layers[4].output\n",
    "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)\n",
    "\n",
    "new_model = keras.Model(\n",
    "    inputs=[title, text_body, tags],\n",
    "    outputs=[priority, department, difficulty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(new_model, \"updated_ticket_classifier.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Subclassing the Model class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Rewriting our previous example as a subclassed model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple subclassed model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're in charge, you can write a call and init hovewer you like without the graph-like constraints of Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_departments):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
    "        self.department_classifier = layers.Dense(\n",
    "            num_departments, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "\n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)\n",
    "        department = self.department_classifier(features)\n",
    "        return priority, department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = CustomerTicketModel(num_departments=4)\n",
    "\n",
    "priority, department = model(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 19ms/step - loss: 36.7537 - output_1_loss: 0.3170 - output_2_loss: 36.4367 - output_1_mean_absolute_error: 0.4840 - output_2_accuracy: 0.1750\n",
      "40/40 [==============================] - 1s 7ms/step - loss: 33.4412 - output_1_loss: 0.3205 - output_2_loss: 33.1208 - output_1_mean_absolute_error: 0.4875 - output_2_accuracy: 0.5758\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit({\"title\": title_data,\n",
    "           \"text_body\": text_body_data,\n",
    "           \"tags\": tags_data},\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data,\n",
    "                \"text_body\": text_body_data,\n",
    "                \"tags\": tags_data},\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict({\"title\": title_data,\n",
    "                                                  \"text_body\": text_body_data,\n",
    "                                                  \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Beware: What subclassed models don't support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is your Python code.  \n",
    "You cannot:\n",
    "1. Use summary()\n",
    "2. Use plot_model()\n",
    "3. Just snap pieces together - this is your model with potencially more room for mistakes and debugging issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Mixing and matching different components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a Functional model that includes a subclassed model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Subclass in Functional Model, A Funtional Model inside a Subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        if num_classes == 2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = Classifier(num_classes=10)(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a subclassed model that includes a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Remember: Use the right tool for the job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what to choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Using built-in training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The standard workflow: `compile()`, `fit()`, `evaluate()`, `predict()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 0.2944 - accuracy: 0.9129 - val_loss: 0.1508 - val_accuracy: 0.9555\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1661 - accuracy: 0.9527 - val_loss: 0.1247 - val_accuracy: 0.9656\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.1387 - accuracy: 0.9630 - val_loss: 0.1155 - val_accuracy: 0.9700\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1157 - accuracy: 0.9718\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom metric by subclassing the `Metric` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.2970 - accuracy: 0.9119 - rmse: 7.1787 - val_loss: 0.1565 - val_accuracy: 0.9537 - val_rmse: 7.3448\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.1679 - accuracy: 0.9537 - rmse: 7.3537 - val_loss: 0.1228 - val_accuracy: 0.9677 - val_rmse: 7.4049\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.1399 - accuracy: 0.9631 - rmse: 7.3904 - val_loss: 0.1161 - val_accuracy: 0.9705 - val_rmse: 7.4240\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1095 - accuracy: 0.9716 - rmse: 7.4361\n"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The EarlyStopping and ModelCheckpoint callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Using the `callbacks` argument in the `fit()` method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.2976 - accuracy: 0.9123 - val_loss: 0.1554 - val_accuracy: 0.9549\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.1663 - accuracy: 0.9537 - val_loss: 0.1211 - val_accuracy: 0.9648\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 0.1388 - accuracy: 0.9627 - val_loss: 0.1166 - val_accuracy: 0.9716\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 0.1260 - accuracy: 0.9676 - val_loss: 0.1115 - val_accuracy: 0.9723\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 23s 14ms/step - loss: 0.1213 - accuracy: 0.9705 - val_loss: 0.1099 - val_accuracy: 0.9743\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.1105 - accuracy: 0.9730 - val_loss: 0.1068 - val_accuracy: 0.9752\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.1037 - accuracy: 0.9749 - val_loss: 0.1153 - val_accuracy: 0.9764\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.1028 - accuracy: 0.9762 - val_loss: 0.1212 - val_accuracy: 0.9770\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1002 - accuracy: 0.9769 - val_loss: 0.1147 - val_accuracy: 0.9771\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.0940 - accuracy: 0.9788 - val_loss: 0.1283 - val_accuracy: 0.9770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c983b65dc0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=2,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"checkpoint_path.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a custom callback by subclassing the `Callback` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "                 label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 17s 10ms/step - loss: 0.2993 - accuracy: 0.9108 - val_loss: 0.1558 - val_accuracy: 0.9555\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 13s 9ms/step - loss: 0.1686 - accuracy: 0.9527 - val_loss: 0.1269 - val_accuracy: 0.9657\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1385 - accuracy: 0.9626 - val_loss: 0.1124 - val_accuracy: 0.9710\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 20s 12ms/step - loss: 0.1279 - accuracy: 0.9671 - val_loss: 0.1142 - val_accuracy: 0.9716\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.1187 - accuracy: 0.9707 - val_loss: 0.1178 - val_accuracy: 0.9733\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.1115 - accuracy: 0.9729 - val_loss: 0.1203 - val_accuracy: 0.9745\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 23s 14ms/step - loss: 0.1071 - accuracy: 0.9743 - val_loss: 0.1151 - val_accuracy: 0.9754\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 0.1037 - accuracy: 0.9761 - val_loss: 0.1284 - val_accuracy: 0.9759\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 0.0993 - accuracy: 0.9776 - val_loss: 0.1270 - val_accuracy: 0.9771\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.0949 - accuracy: 0.9787 - val_loss: 0.1322 - val_accuracy: 0.9767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c9e67eef10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=[LossHistory()],\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Monitoring and visualization with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 14s 8ms/step - loss: 0.2922 - accuracy: 0.9134 - val_loss: 0.1489 - val_accuracy: 0.9579\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 13s 9ms/step - loss: 0.1668 - accuracy: 0.9531 - val_loss: 0.1215 - val_accuracy: 0.9676\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1399 - accuracy: 0.9635 - val_loss: 0.1197 - val_accuracy: 0.9702\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1295 - accuracy: 0.9673 - val_loss: 0.1207 - val_accuracy: 0.9701\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 13s 9ms/step - loss: 0.1176 - accuracy: 0.9703 - val_loss: 0.1116 - val_accuracy: 0.9737\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1146 - accuracy: 0.9727 - val_loss: 0.1106 - val_accuracy: 0.9756\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1090 - accuracy: 0.9739 - val_loss: 0.1025 - val_accuracy: 0.9780\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1027 - accuracy: 0.9760 - val_loss: 0.1097 - val_accuracy: 0.9776\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.0981 - accuracy: 0.9777 - val_loss: 0.1128 - val_accuracy: 0.9779\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.0999 - accuracy: 0.9787 - val_loss: 0.1211 - val_accuracy: 0.9765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c983e36850>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/full_path_to_your_log_dir\",\n",
    ")\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          validation_data=(val_images, val_labels),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 10584), started 0:04:22 ago. (Use '!kill 10584' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-87eb5a0e2b3b06b2\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-87eb5a0e2b3b06b2\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /full_path_to_your_log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Writing your own training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Training versus inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Low-level usage of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"result: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### A complete training and evaluation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the training step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: resetting the metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the loop itself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step evaluation loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Leveraging fit() with a custom training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom training step to use with `fit()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter07_working-with-keras.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
