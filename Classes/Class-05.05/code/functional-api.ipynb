{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Lets see how else we can build models.\n",
    "\n",
    "Some of the examples are from [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Different ways to build Keras models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras - easy to start with but also possible to provide deep dives for those who need it.  \n",
    "NLP and Image Processing are such needs.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The `Sequential` class**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thing to remember - Keras is API based.  \n",
    "Sequential is a list of stacked layers - there lies its first limitation.\n",
    "So:\n",
    "1. Only feedforward models.\n",
    "2. Only one input (not for example a text/picture and its metadata)\n",
    "3. Only one output (not for example multiple regression/classification predictions for one data point)\n",
    "4. Linear topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 16:53:39.703579: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Incrementally building a Sequential model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like in Python list!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Weights for model sequential_1 have not yet been created. Weights are created when the Model is first called on inputs or `build()` is called with an `input_shape`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bv/f5hcp35577g3y7qmz1mbdbr80000gn/T/ipykernel_27144/2402420200.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mweights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2733\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2734\u001b[0m     \"\"\"\n\u001b[0;32m-> 2735\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dedup_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_undeduplicated_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2737\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_undeduplicated_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2738\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_undeduplicated_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2739\u001b[0m     \u001b[0;34m\"\"\"Returns the undeduplicated list of all layer variables/weights.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2740\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2741\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2742\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_tracked_trackables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36m_assert_weights_created\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;31m# When the graph has not been initialized, use the Model's implementation to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;31m# to check if the weights has been created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunctional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=bad-super-call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_assert_weights_created\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2931\u001b[0m       \u001b[0;31m# been invoked yet, this will cover both sequential and subclass model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2932\u001b[0m       \u001b[0;31m# Also make sure to exclude Model class itself which has build() defined.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2933\u001b[0;31m       raise ValueError(f'Weights for model {self.name} have not yet been '\n\u001b[0m\u001b[1;32m   2934\u001b[0m                        \u001b[0;34m'created. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2935\u001b[0m                        \u001b[0;34m'Weights are created when the Model is first called on '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Weights for model sequential_1 have not yet been created. Weights are created when the Model is first called on inputs or `build()` is called with an `input_shape`."
     ]
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error - model is not built yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Calling a model for the first time to build it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_2/kernel:0' shape=(3, 64) dtype=float32, numpy=\n",
       " array([[ 1.78957105e-01, -1.39682785e-01, -2.75479764e-01,\n",
       "          2.78863668e-01,  1.19591773e-01, -1.76413059e-02,\n",
       "         -2.12886453e-01,  2.91899085e-01, -2.56226659e-01,\n",
       "         -2.35388651e-01, -8.89932960e-02,  2.42581546e-01,\n",
       "         -3.89504135e-02,  1.07996970e-01, -1.97498605e-01,\n",
       "          2.78139949e-01, -1.50649816e-01,  8.29148591e-02,\n",
       "         -1.15714252e-01, -2.41442621e-02,  6.39248788e-02,\n",
       "         -8.53826106e-02, -1.65432364e-01, -9.35242772e-02,\n",
       "         -1.18078575e-01,  2.59984434e-02, -2.66795725e-01,\n",
       "         -1.17526770e-01,  8.09616446e-02, -1.65768325e-01,\n",
       "          2.42937088e-01,  2.30499208e-01, -2.46602267e-01,\n",
       "         -1.92497998e-01,  9.10550952e-02,  4.54347432e-02,\n",
       "          9.25977528e-02, -3.23057175e-05,  2.67388999e-01,\n",
       "         -2.26934984e-01,  2.39322186e-02, -2.41931975e-02,\n",
       "          2.89157093e-01, -2.97595263e-01,  1.05401695e-01,\n",
       "          2.81434953e-02,  2.18852222e-01, -2.83068925e-01,\n",
       "         -6.68441951e-02,  2.92244077e-01, -2.08782703e-01,\n",
       "          2.48230398e-01,  2.40636945e-01,  7.64742494e-02,\n",
       "         -4.10147905e-02,  2.16431618e-02, -3.29084992e-02,\n",
       "          1.04601830e-01,  4.52670455e-03,  8.87823105e-02,\n",
       "          2.26556003e-01,  1.26027942e-01,  1.85077012e-01,\n",
       "          1.02544725e-02],\n",
       "        [ 1.12324834e-01,  3.99441421e-02, -1.22184977e-01,\n",
       "          2.86410570e-01,  1.53825283e-01,  2.03948855e-01,\n",
       "         -1.87601641e-01, -5.45297712e-02, -3.14877033e-02,\n",
       "         -1.89786255e-02, -1.70661345e-01, -4.04326022e-02,\n",
       "          1.47380888e-01, -2.67156661e-01, -2.81835765e-01,\n",
       "          1.94865376e-01, -1.10341445e-01, -4.22147810e-02,\n",
       "          2.24577904e-01, -1.16046742e-01, -1.05370313e-01,\n",
       "         -5.90867996e-02, -1.04235381e-01, -2.67753422e-01,\n",
       "          2.85926223e-01,  3.65394354e-02,  8.18145275e-02,\n",
       "         -2.22592056e-01,  1.26752406e-01,  2.81292260e-01,\n",
       "          1.16344839e-01,  2.76110828e-01, -4.53988612e-02,\n",
       "         -8.23394209e-02,  2.82118380e-01, -2.40759119e-01,\n",
       "          1.54829204e-01, -2.66836822e-01,  1.31306887e-01,\n",
       "          7.27878511e-02,  5.33236563e-02,  2.98483610e-01,\n",
       "         -3.06701064e-02,  1.00948334e-01,  2.75970578e-01,\n",
       "         -2.29828268e-01, -5.02645522e-02,  6.87091351e-02,\n",
       "         -1.05125010e-01,  2.26698279e-01,  2.67081916e-01,\n",
       "          2.87389874e-01, -1.30757004e-01, -7.60228932e-02,\n",
       "          7.84740448e-02,  1.65242791e-01, -1.46882027e-01,\n",
       "          2.27570534e-03,  8.64075124e-02,  6.52204752e-02,\n",
       "          1.13383263e-01,  1.63024873e-01, -1.33988470e-01,\n",
       "          2.17373848e-01],\n",
       "        [ 1.53826773e-01, -9.48414207e-03,  1.60869479e-01,\n",
       "         -1.52420998e-02, -2.59389281e-01, -2.92753577e-02,\n",
       "         -1.64937347e-01,  1.01706833e-01,  2.92473495e-01,\n",
       "         -2.59364605e-01,  2.71586835e-01, -8.91931355e-02,\n",
       "          1.08175248e-01,  1.96609199e-02, -6.97280616e-02,\n",
       "          2.57430255e-01, -1.28232017e-01,  1.46928340e-01,\n",
       "          1.69460922e-01, -7.40695447e-02,  1.21045560e-01,\n",
       "          4.12788391e-02, -2.32548386e-01,  8.94883275e-03,\n",
       "         -1.87402576e-01,  2.55679369e-01, -1.46876961e-01,\n",
       "          2.59506583e-01, -5.21187931e-02, -2.92377830e-01,\n",
       "          2.34548151e-01,  4.97270823e-02, -2.30538309e-01,\n",
       "         -5.78202456e-02,  1.47518516e-01,  4.92691696e-02,\n",
       "          1.69423819e-02,  2.92051375e-01, -1.91175997e-01,\n",
       "          3.40608358e-02,  1.25941038e-02, -2.12132603e-01,\n",
       "         -1.54820994e-01,  3.93351912e-03,  9.36161876e-02,\n",
       "         -1.02226883e-01, -2.09536761e-01,  9.70852375e-03,\n",
       "          2.78706729e-01, -4.28019762e-02,  2.68692434e-01,\n",
       "          1.27685577e-01, -4.40902710e-02, -1.99921131e-02,\n",
       "         -8.60248804e-02, -4.09959555e-02, -1.14819348e-01,\n",
       "         -6.60691410e-02, -2.29380697e-01, -2.56114304e-02,\n",
       "         -4.69481051e-02, -2.46395916e-01, -1.43110380e-01,\n",
       "          9.25639570e-02]], dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(64, 10) dtype=float32, numpy=\n",
       " array([[-0.1489804 , -0.15824324, -0.13955073,  0.23149261,  0.13766736,\n",
       "         -0.16281992,  0.25498244, -0.1338773 ,  0.23358783, -0.07336487],\n",
       "        [ 0.16689965, -0.00531366, -0.1887033 , -0.07324165, -0.04938936,\n",
       "         -0.03118384,  0.02798897, -0.03418413,  0.23748335, -0.225057  ],\n",
       "        [-0.09857316, -0.22316426, -0.03135687,  0.24843267,  0.23661175,\n",
       "          0.16956925,  0.00570866, -0.09889476, -0.2380364 , -0.2276277 ],\n",
       "        [-0.06654873, -0.11642785,  0.08233422, -0.10741511, -0.15255964,\n",
       "          0.07882431,  0.07863027,  0.08588204, -0.17113334, -0.08596188],\n",
       "        [ 0.11528528, -0.02441788, -0.27612507,  0.16766909,  0.05375659,\n",
       "         -0.25811628,  0.04875201, -0.0882543 , -0.19705081,  0.2563257 ],\n",
       "        [-0.15786429,  0.1479742 ,  0.10996467, -0.18169436, -0.03668365,\n",
       "         -0.2531561 ,  0.01785991, -0.21983328, -0.21503645, -0.03515872],\n",
       "        [ 0.08986592, -0.18428345,  0.25691894, -0.1611878 , -0.03982991,\n",
       "          0.0703643 ,  0.04456082, -0.28341338, -0.17020753, -0.22552694],\n",
       "        [-0.20066217,  0.11842215, -0.24269798, -0.08290987,  0.1379095 ,\n",
       "          0.17959931,  0.03421882,  0.1441052 ,  0.01859969, -0.10863106],\n",
       "        [ 0.18303075, -0.07115494, -0.0845741 ,  0.03708217, -0.05184172,\n",
       "         -0.03065389, -0.27965218, -0.26036435, -0.14493203,  0.09685877],\n",
       "        [ 0.12473747,  0.14683095, -0.27742156,  0.0032368 ,  0.15366548,\n",
       "          0.13976654, -0.17765008,  0.281158  ,  0.05700904, -0.2644087 ],\n",
       "        [-0.09665035, -0.16990271,  0.26923332,  0.17258826,  0.05696672,\n",
       "          0.13288933,  0.27290776,  0.2615383 , -0.18772596, -0.01768455],\n",
       "        [ 0.12754801, -0.16850385, -0.124855  ,  0.14342219, -0.23887801,\n",
       "          0.2610083 ,  0.08882686, -0.18807784, -0.11049272,  0.27254197],\n",
       "        [-0.1684712 ,  0.13989758, -0.19791809,  0.2331638 ,  0.08118862,\n",
       "          0.08983549,  0.10777432, -0.07314925,  0.23684302,  0.00402555],\n",
       "        [ 0.0764071 ,  0.2480888 ,  0.04466429,  0.06127316, -0.04662995,\n",
       "          0.23498616, -0.12088715,  0.2535824 ,  0.1559346 ,  0.26334158],\n",
       "        [ 0.21740112,  0.10645908,  0.27718326, -0.2621042 , -0.13645859,\n",
       "         -0.21163073, -0.258053  ,  0.2187489 ,  0.02037358, -0.1498933 ],\n",
       "        [-0.16743264,  0.06471613,  0.13454086, -0.10139409, -0.12739432,\n",
       "          0.18430516,  0.04153961, -0.26533234,  0.04772806,  0.09570974],\n",
       "        [ 0.18978783, -0.08220178,  0.10252357, -0.14083289, -0.17562482,\n",
       "          0.02105775, -0.14216141,  0.06275502,  0.21815047,  0.24226704],\n",
       "        [-0.22233643, -0.24874291,  0.14397505, -0.03160968, -0.17404951,\n",
       "          0.20844856,  0.21624741,  0.2166014 , -0.1274935 ,  0.25991663],\n",
       "        [ 0.09323519, -0.10027459, -0.2015765 , -0.15428483, -0.09726867,\n",
       "         -0.16108793, -0.07393527,  0.1520164 , -0.2611647 ,  0.28388175],\n",
       "        [-0.21099027,  0.18366152, -0.21376726,  0.1995669 ,  0.21438539,\n",
       "         -0.04113887, -0.13551703, -0.1674141 ,  0.20304629, -0.13609321],\n",
       "        [-0.09359649, -0.13552946, -0.07227063, -0.16777004,  0.00701803,\n",
       "          0.20719966,  0.2673997 ,  0.19592541,  0.08878803, -0.19711605],\n",
       "        [-0.00210816, -0.20501365,  0.24682525,  0.22666517,  0.18853766,\n",
       "          0.2117185 ,  0.04979017,  0.02283427,  0.25106153, -0.1830427 ],\n",
       "        [ 0.06393826, -0.23114435,  0.22023961,  0.12264535, -0.21296264,\n",
       "         -0.1416485 ,  0.24568573, -0.09484972,  0.00596154,  0.1618104 ],\n",
       "        [-0.13298084, -0.07106893,  0.14849424, -0.08519678,  0.07571715,\n",
       "          0.18526193, -0.04019399,  0.1440849 ,  0.26202092,  0.20631507],\n",
       "        [ 0.15947694,  0.16168618,  0.16522571, -0.1609011 , -0.03299803,\n",
       "         -0.17721519, -0.05470413, -0.20689438,  0.09486946, -0.17570281],\n",
       "        [ 0.03738087, -0.20708066, -0.08514592, -0.08480349,  0.25865993,\n",
       "         -0.03517739, -0.12573747, -0.0013603 , -0.01074615,  0.18077853],\n",
       "        [-0.20937172,  0.27566704, -0.20508134,  0.0274969 , -0.05030335,\n",
       "         -0.14543122, -0.269849  , -0.02219084, -0.02225167, -0.13650712],\n",
       "        [-0.19725814,  0.02347869, -0.01639733, -0.22698995, -0.14504296,\n",
       "          0.18158922,  0.07354504, -0.12271112, -0.03825691,  0.11754036],\n",
       "        [-0.17221203,  0.25737056,  0.02777517, -0.00054258,  0.23659244,\n",
       "         -0.12205783,  0.282743  ,  0.03200155, -0.08118053, -0.03466347],\n",
       "        [-0.2049725 ,  0.09156117,  0.00692713, -0.09601395,  0.20408249,\n",
       "          0.07523128,  0.20261908,  0.14981651,  0.20084071, -0.26137218],\n",
       "        [ 0.20801762,  0.13055754,  0.19498065,  0.0707466 ,  0.00599235,\n",
       "          0.02058649,  0.19252497,  0.10526866, -0.15771832,  0.05828446],\n",
       "        [ 0.04519945,  0.09295073,  0.12328643,  0.28114173, -0.01580796,\n",
       "         -0.14736219, -0.091226  , -0.02056843, -0.20473231, -0.03905943],\n",
       "        [ 0.09270313,  0.26757303,  0.20260692,  0.13062692,  0.04690456,\n",
       "         -0.15247403,  0.27756885,  0.23982921,  0.09887329,  0.25971934],\n",
       "        [-0.26408222, -0.2584359 ,  0.00251949,  0.12710544, -0.2524554 ,\n",
       "          0.14512423,  0.05251783, -0.25959218, -0.1705474 ,  0.02432927],\n",
       "        [ 0.25136444, -0.15436596,  0.09287849, -0.15383168, -0.20299578,\n",
       "          0.22319773,  0.16999838,  0.23190829, -0.0751458 , -0.03545567],\n",
       "        [ 0.27590027,  0.09144393,  0.02992231, -0.00800046,  0.1800422 ,\n",
       "         -0.16346222,  0.24434862,  0.16333553,  0.15729049,  0.27678248],\n",
       "        [ 0.08541292,  0.28380302,  0.13610041,  0.18431163, -0.0155206 ,\n",
       "          0.14872819, -0.2664382 ,  0.14832643, -0.27122822, -0.160896  ],\n",
       "        [-0.23331416, -0.11419824, -0.05966315,  0.18430573, -0.2535816 ,\n",
       "          0.16012126, -0.2171886 , -0.02530673,  0.0174678 ,  0.15403411],\n",
       "        [-0.14833552, -0.11548358, -0.14104883,  0.23097321,  0.0090107 ,\n",
       "         -0.09882361, -0.16845965, -0.04202041, -0.14576638, -0.01510674],\n",
       "        [-0.11530402, -0.02215946, -0.04081036,  0.08214551, -0.2766591 ,\n",
       "          0.20691231, -0.1762079 , -0.05688167, -0.18012878, -0.21903913],\n",
       "        [ 0.22802678, -0.13923757,  0.01203617, -0.23686232, -0.2516352 ,\n",
       "          0.13835263,  0.18419954,  0.07125771, -0.25529808, -0.16226444],\n",
       "        [-0.25431794, -0.25290233, -0.13685411,  0.10249037,  0.00956231,\n",
       "         -0.28459802, -0.02108234, -0.10762888, -0.22139671, -0.22174844],\n",
       "        [-0.23033613,  0.09865823, -0.09717642, -0.09823976,  0.13900247,\n",
       "          0.26841405,  0.00206232, -0.17221305, -0.26828274,  0.1297563 ],\n",
       "        [-0.141191  , -0.21054837,  0.03125674, -0.20891014, -0.26860282,\n",
       "         -0.09518965,  0.23601952,  0.15363628,  0.2800915 , -0.20858577],\n",
       "        [ 0.09038091,  0.19800436,  0.00507015,  0.18095681, -0.24807535,\n",
       "          0.00139832, -0.14701214, -0.0385671 ,  0.20490158, -0.11174521],\n",
       "        [-0.21262959,  0.09263965,  0.19197643, -0.01051128,  0.19959027,\n",
       "         -0.18673302,  0.25872925,  0.25799718,  0.10674483,  0.2037288 ],\n",
       "        [ 0.10984886, -0.06275482,  0.19969636, -0.04084559, -0.07010429,\n",
       "         -0.20404175, -0.14935113, -0.21902208, -0.2598325 ,  0.22078517],\n",
       "        [ 0.17472684, -0.0307712 , -0.24398714,  0.26544753, -0.10006279,\n",
       "          0.14908576,  0.02619976, -0.21227072,  0.26331517,  0.16410112],\n",
       "        [-0.12822175, -0.21703592, -0.07242705,  0.1797564 , -0.10886779,\n",
       "          0.10899869, -0.2375505 ,  0.17466182, -0.10396165, -0.14520752],\n",
       "        [ 0.26581994, -0.20106888, -0.1189561 ,  0.05990607, -0.10403362,\n",
       "         -0.06961086,  0.06744996,  0.25210056, -0.24291857,  0.12825826],\n",
       "        [ 0.22023425,  0.03436041,  0.1699501 , -0.05960476,  0.03371125,\n",
       "         -0.00587755,  0.17795613,  0.13030133,  0.14015374, -0.2455386 ],\n",
       "        [ 0.02731836, -0.02379212,  0.2534612 ,  0.09720105, -0.09666201,\n",
       "         -0.2259004 ,  0.14529538,  0.06816801, -0.1886141 , -0.26760846],\n",
       "        [-0.07547723,  0.05492193,  0.02565405, -0.10247542, -0.2713395 ,\n",
       "          0.05063167,  0.18505156, -0.05337921,  0.09394875, -0.07741554],\n",
       "        [-0.22968264,  0.08758241,  0.25320342,  0.18094495, -0.17732462,\n",
       "         -0.10850506, -0.08899122,  0.26225784, -0.12906764, -0.22451797],\n",
       "        [-0.07045439, -0.07283323, -0.04960307,  0.10588855,  0.22663996,\n",
       "          0.16724792, -0.07781614, -0.04623674, -0.17673364,  0.28365698],\n",
       "        [-0.02208757, -0.04664773, -0.16095358, -0.02518535, -0.07999906,\n",
       "          0.09917283, -0.10594156,  0.1426175 , -0.12751251, -0.2809841 ],\n",
       "        [ 0.01690051, -0.04670829,  0.24615368, -0.15550643, -0.05373739,\n",
       "         -0.12627211, -0.1503419 , -0.05794671,  0.24654719, -0.20253576],\n",
       "        [ 0.1516189 ,  0.21796301,  0.05671141, -0.17357606, -0.07552618,\n",
       "          0.23561338, -0.16329949,  0.06789783, -0.06459889, -0.2597253 ],\n",
       "        [-0.03451568,  0.03615493,  0.03627178, -0.165865  , -0.24003002,\n",
       "         -0.05614568, -0.24765497,  0.24578282,  0.19761422,  0.08601308],\n",
       "        [ 0.10474572,  0.0143055 ,  0.1934939 , -0.08817296,  0.01720065,\n",
       "          0.21746191, -0.23282501, -0.18968885, -0.093344  ,  0.05985448],\n",
       "        [ 0.25090978, -0.04194255,  0.15717956,  0.19083142,  0.12347391,\n",
       "          0.08744749, -0.07181075, -0.21549138, -0.20739907, -0.13874821],\n",
       "        [ 0.25915697,  0.1475901 ,  0.18611944,  0.20857057,  0.24325237,\n",
       "         -0.14865853,  0.11063698,  0.25812206,  0.05753204,  0.19349456],\n",
       "        [-0.28192186, -0.26790276,  0.092832  , -0.2452807 ,  0.23369494,\n",
       "          0.27821967,  0.1880635 , -0.13670896, -0.008356  ,  0.0699341 ],\n",
       "        [ 0.24549863,  0.2522979 , -0.02585921,  0.07886022,  0.16593975,\n",
       "         -0.23295054, -0.19815564, -0.2442627 ,  0.2518936 ,  0.00870758]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build(input_shape=(None, 3))\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The summary method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Naming models and layers with the `name` argument**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can name every layer, model and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_example_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_first_layer (Dense)      (None, 64)                256       \n",
      "                                                                 \n",
      " my_last_layer (Dense)       (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name=\"my_example_model\")\n",
    "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
    "model.build((None, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Specifying the input shape of your model in advance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that you can see the summary without actually building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple Functional model with two `Dense` layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)  #takes \n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what we did - add another layer on top of the previous one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = layers.Dense(64, activation=\"relu\")(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 64])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_input (InputLayer)       [(None, 3)]               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Multi-input, multi-output models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A multi-input, multi-output Functional model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets image a usecase of dealing with support tickets.  \n",
    "We need to move tickets to appropriate departaments. What we know:  \n",
    "1. Title of ticket (text)\n",
    "2. Text of the ticket (text)\n",
    "3. Tags added by the user (one-hot encoding)\n",
    "\n",
    "We expect to know:\n",
    "1. Priority of the ticket (regression)\n",
    "2. Departament where to move the ticket (classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 10000 #this is what we did on bert - how many words do we use from the dictionary\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "\n",
    "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
    "\n",
    "features = layers.Concatenate()([title, text_body, tags])\n",
    "features = layers.Dense(64, activation=\"relu\")(features)\n",
    "\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(\n",
    "    num_departments, activation=\"softmax\", name=\"department\")(features)\n",
    "\n",
    "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Training a multi-input, multi-output model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing lists of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 27ms/step - loss: 27.0280 - priority_loss: 0.3182 - department_loss: 26.7098 - priority_mean_absolute_error: 0.4834 - department_accuracy: 0.2594\n",
      "40/40 [==============================] - 1s 11ms/step - loss: 26.7166 - priority_loss: 0.3259 - department_loss: 26.3907 - priority_mean_absolute_error: 0.4908 - department_accuracy: 0.5625\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1280\n",
    "\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags)) # rabdomly making data \n",
    "\n",
    "priority_data = np.random.random(size=(num_samples, 1)) # randomly making the labels\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))  #randomly making the labels\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit([title_data, text_body_data, tags_data],\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate([title_data, text_body_data, tags_data],\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing dicts of input & target arrays**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are using names - for complex models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 28ms/step - loss: 35.3133 - priority_loss: 0.3259 - department_loss: 34.9875 - priority_mean_absolute_error: 0.4908 - department_accuracy: 0.2477\n",
      "40/40 [==============================] - 1s 10ms/step - loss: 30.6176 - priority_loss: 0.3259 - department_loss: 30.2917 - priority_mean_absolute_error: 0.4908 - department_accuracy: 0.1234\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"},\n",
    "              metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]})\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "          {\"priority\": priority_data, \"department\": department_data},\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "               {\"priority\": priority_data, \"department\": department_data})\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The power of the Functional API: Access to layer connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Plot Model](../img/plot-ticketmodel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://www.manning.com/books/deep-learning-with-python  \n",
    "\n",
    "This can mean retrieving fetures from another models and reusing components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Retrieving the inputs or outputs of a layer in a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x7f85b5f66e90>,\n",
       " <keras.engine.input_layer.InputLayer at 0x7f85b5f66ad0>,\n",
       " <keras.engine.input_layer.InputLayer at 0x7f85bf81abd0>,\n",
       " <keras.layers.merge.Concatenate at 0x7f85bf81a590>,\n",
       " <keras.layers.core.dense.Dense at 0x7f85bf82a890>,\n",
       " <keras.layers.core.dense.Dense at 0x7f85befdbfd0>,\n",
       " <keras.layers.core.dense.Dense at 0x7f85bf892fd0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'title')>,\n",
       " <KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'text_body')>,\n",
       " <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'tags')>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 20100) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a new model by reusing intermediate layer outputs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding new prediction to the existing model. Easy! \n",
    "Now: 3 categories of difficulty resolving the ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = model.layers[4].output\n",
    "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)\n",
    "\n",
    "new_model = keras.Model(\n",
    "    inputs=[title, text_body, tags],\n",
    "    outputs=[priority, department, difficulty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(new_model, \"updated_ticket_classifier.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Subclassing the Model class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Rewriting our previous example as a subclassed model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple subclassed model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're in charge, you can write a call and init hovewer you like without the graph-like constraints of Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_departments):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
    "        self.department_classifier = layers.Dense(\n",
    "            num_departments, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "\n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)\n",
    "        department = self.department_classifier(features)\n",
    "        return priority, department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = CustomerTicketModel(num_departments=4)\n",
    "\n",
    "priority, department = model(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 19ms/step - loss: 36.7537 - output_1_loss: 0.3170 - output_2_loss: 36.4367 - output_1_mean_absolute_error: 0.4840 - output_2_accuracy: 0.1750\n",
      "40/40 [==============================] - 1s 7ms/step - loss: 33.4412 - output_1_loss: 0.3205 - output_2_loss: 33.1208 - output_1_mean_absolute_error: 0.4875 - output_2_accuracy: 0.5758\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit({\"title\": title_data,\n",
    "           \"text_body\": text_body_data,\n",
    "           \"tags\": tags_data},\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data,\n",
    "                \"text_body\": text_body_data,\n",
    "                \"tags\": tags_data},\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict({\"title\": title_data,\n",
    "                                                  \"text_body\": text_body_data,\n",
    "                                                  \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Beware: What subclassed models don't support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is your Python code.  \n",
    "You cannot:\n",
    "1. Use summary()\n",
    "2. Use plot_model()\n",
    "3. Just snap pieces together - this is your model with potencially more room for mistakes and debugging issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Mixing and matching different components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a Functional model that includes a subclassed model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Subclass in Functional Model, A Funtional Model inside a Subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        if num_classes == 2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = Classifier(num_classes=10)(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a subclassed model that includes a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Remember: Use the right tool for the job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what to choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Using built-in training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The standard workflow: `compile()`, `fit()`, `evaluate()`, `predict()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 0.2944 - accuracy: 0.9129 - val_loss: 0.1508 - val_accuracy: 0.9555\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1661 - accuracy: 0.9527 - val_loss: 0.1247 - val_accuracy: 0.9656\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.1387 - accuracy: 0.9630 - val_loss: 0.1155 - val_accuracy: 0.9700\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1157 - accuracy: 0.9718\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom metric by subclassing the `Metric` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.2970 - accuracy: 0.9119 - rmse: 7.1787 - val_loss: 0.1565 - val_accuracy: 0.9537 - val_rmse: 7.3448\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.1679 - accuracy: 0.9537 - rmse: 7.3537 - val_loss: 0.1228 - val_accuracy: 0.9677 - val_rmse: 7.4049\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.1399 - accuracy: 0.9631 - rmse: 7.3904 - val_loss: 0.1161 - val_accuracy: 0.9705 - val_rmse: 7.4240\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1095 - accuracy: 0.9716 - rmse: 7.4361\n"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The EarlyStopping and ModelCheckpoint callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Using the `callbacks` argument in the `fit()` method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.2976 - accuracy: 0.9123 - val_loss: 0.1554 - val_accuracy: 0.9549\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.1663 - accuracy: 0.9537 - val_loss: 0.1211 - val_accuracy: 0.9648\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 0.1388 - accuracy: 0.9627 - val_loss: 0.1166 - val_accuracy: 0.9716\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 0.1260 - accuracy: 0.9676 - val_loss: 0.1115 - val_accuracy: 0.9723\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 23s 14ms/step - loss: 0.1213 - accuracy: 0.9705 - val_loss: 0.1099 - val_accuracy: 0.9743\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.1105 - accuracy: 0.9730 - val_loss: 0.1068 - val_accuracy: 0.9752\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.1037 - accuracy: 0.9749 - val_loss: 0.1153 - val_accuracy: 0.9764\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.1028 - accuracy: 0.9762 - val_loss: 0.1212 - val_accuracy: 0.9770\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1002 - accuracy: 0.9769 - val_loss: 0.1147 - val_accuracy: 0.9771\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.0940 - accuracy: 0.9788 - val_loss: 0.1283 - val_accuracy: 0.9770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c983b65dc0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=2,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"checkpoint_path.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a custom callback by subclassing the `Callback` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "                 label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 17s 10ms/step - loss: 0.2993 - accuracy: 0.9108 - val_loss: 0.1558 - val_accuracy: 0.9555\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 13s 9ms/step - loss: 0.1686 - accuracy: 0.9527 - val_loss: 0.1269 - val_accuracy: 0.9657\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1385 - accuracy: 0.9626 - val_loss: 0.1124 - val_accuracy: 0.9710\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 20s 12ms/step - loss: 0.1279 - accuracy: 0.9671 - val_loss: 0.1142 - val_accuracy: 0.9716\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.1187 - accuracy: 0.9707 - val_loss: 0.1178 - val_accuracy: 0.9733\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.1115 - accuracy: 0.9729 - val_loss: 0.1203 - val_accuracy: 0.9745\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 23s 14ms/step - loss: 0.1071 - accuracy: 0.9743 - val_loss: 0.1151 - val_accuracy: 0.9754\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 0.1037 - accuracy: 0.9761 - val_loss: 0.1284 - val_accuracy: 0.9759\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 0.0993 - accuracy: 0.9776 - val_loss: 0.1270 - val_accuracy: 0.9771\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.0949 - accuracy: 0.9787 - val_loss: 0.1322 - val_accuracy: 0.9767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c9e67eef10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=[LossHistory()],\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Monitoring and visualization with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 14s 8ms/step - loss: 0.2922 - accuracy: 0.9134 - val_loss: 0.1489 - val_accuracy: 0.9579\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 13s 9ms/step - loss: 0.1668 - accuracy: 0.9531 - val_loss: 0.1215 - val_accuracy: 0.9676\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1399 - accuracy: 0.9635 - val_loss: 0.1197 - val_accuracy: 0.9702\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1295 - accuracy: 0.9673 - val_loss: 0.1207 - val_accuracy: 0.9701\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 13s 9ms/step - loss: 0.1176 - accuracy: 0.9703 - val_loss: 0.1116 - val_accuracy: 0.9737\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1146 - accuracy: 0.9727 - val_loss: 0.1106 - val_accuracy: 0.9756\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1090 - accuracy: 0.9739 - val_loss: 0.1025 - val_accuracy: 0.9780\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1027 - accuracy: 0.9760 - val_loss: 0.1097 - val_accuracy: 0.9776\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.0981 - accuracy: 0.9777 - val_loss: 0.1128 - val_accuracy: 0.9779\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.0999 - accuracy: 0.9787 - val_loss: 0.1211 - val_accuracy: 0.9765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c983e36850>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/full_path_to_your_log_dir\",\n",
    ")\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          validation_data=(val_images, val_labels),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 10584), started 0:04:22 ago. (Use '!kill 10584' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-87eb5a0e2b3b06b2\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-87eb5a0e2b3b06b2\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /full_path_to_your_log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Writing your own training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Training versus inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Low-level usage of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"result: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### A complete training and evaluation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the training step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: resetting the metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the loop itself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step evaluation loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Leveraging fit() with a custom training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom training step to use with `fit()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter07_working-with-keras.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
